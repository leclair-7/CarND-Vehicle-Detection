{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from vehicle_detection_utilities import *\n",
    "\n",
    "# Read in image similar to one shown above \n",
    "image = mpimg.imread('test_image.jpg')\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "#this is how to call the it..\n",
    "#get_feature_vector(i, **search_win_params)\n",
    "def get_feature_vector(image_filename, **parameters):\n",
    "    return get_img_features(image_filename, **parameters)\n",
    "    \n",
    "search_win_params_classify = {\n",
    "'color_space' : 'YUV',\n",
    "'orient' : 11,\n",
    "'pix_per_cell' : 16,\n",
    "'cell_per_block' : 2,\n",
    "'hog_channel' : \"ALL\",\n",
    "'fromFile' : False\n",
    "}\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='YUV', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = get_feature_vector(test_img, **search_win_params_classify)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "\n",
    "#GENERATES WINDOWS\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "class DetectorMediator:\n",
    "    def __init__(self,image):        \n",
    "        \n",
    "        self.boxes_que = deque(maxlen=5)\n",
    "        self.heatmap = None\n",
    "        self.image = image\n",
    "    \n",
    "    def add_heat(self, heatmap, bbox_list):\n",
    "        # Iterate through list of bboxes\n",
    "        for box in bbox_list:\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1            \n",
    "        return heatmap\n",
    "    \n",
    "    def apply_threshold(self, threshold):\n",
    "        \n",
    "        checkmap = np.copy(self.heatmap)\n",
    "        checkmap[checkmap <= threshold] = 0        \n",
    "        return checkmap\n",
    "    \n",
    "    def generate_heatmap(self):\n",
    "        '''\n",
    "        Generates the heatmap\n",
    "        \n",
    "        Doesn't return anything because it updates an instance var.\n",
    "        \n",
    "        This may affect runtime\n",
    "        '''\n",
    "        self.heatmap = np.zeros_like(self.image[:,:,0]).astype(np.float64)\n",
    "        for boxCoordList in self.boxes_que:\n",
    "            self.heatmap = self.add_heat(self.heatmap, boxCoordList)\n",
    "    \n",
    "    def draw_labeled_bboxes(self, img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        # Return the image\n",
    "        return img\n",
    "        \n",
    "    def detect_vehicles(self, input_image, box_list):\n",
    "        \n",
    "        self.image = input_image\n",
    "        \n",
    "        self.boxes_que.append(box_list)\n",
    "        self.generate_heatmap()\n",
    "        \n",
    "        thresholded_img = self.apply_threshold( 4 )\n",
    "        \n",
    "        labels = label(thresholded_img)\n",
    "        \n",
    "        output_image = self.draw_labeled_bboxes(self.image, labels)\n",
    "        \n",
    "        return output_image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frameno = 0\n",
    "frameno = (frameno + 1) % 5\n",
    "\n",
    "def window_dim(output_img, frameno):\n",
    "    \n",
    "    w_dim = 64\n",
    "    if   frameno % 5 == 0:\n",
    "        w_dim = 64\n",
    "    elif frameno % 4 == 0:\n",
    "        w_dim = 64\n",
    "    elif frameno % 3 == 0:\n",
    "        w_dim = 64\n",
    "    elif frameno % 2 == 0:\n",
    "        w_dim = 64\n",
    "    elif frameno % 1 == 0:\n",
    "        w_dim = 64\n",
    "    return slide_window(output_img, x_start_stop=[None, None], y_start_stop=[475, 700], \n",
    "                    xy_window=(w_dim, w_dim), xy_overlap=(0.85,.85)) \n",
    "\n",
    "search_win_params = {\n",
    "'color_space' : 'YUV',\n",
    "'orient' : 11,\n",
    "'pix_per_cell' : 16,\n",
    "'cell_per_block' : 2,\n",
    "'hog_channel' : \"ALL\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('./test_pipeline/*.jpg')\n",
    "frameno = 0\n",
    "svc = pickle.load( open( \"svc_long_features.p\", \"rb\" ))\n",
    "X_scaler = pickle.load( open(\"scaler_long_features.p\", \"rb\" ))\n",
    "\n",
    "sampleimg = mpimg.imread(\"./test_pipeline/frame707.jpg\")\n",
    "det = DetectorMediator(sampleimg)\n",
    "\n",
    "search_win_params_classify23 = {\n",
    "'color_space' : 'YUV',\n",
    "'orient' : 11,\n",
    "'pix_per_cell' : 16,\n",
    "'cell_per_block' : 2,\n",
    "'hog_channel' : \"ALL\",\n",
    "\n",
    "}\n",
    "\n",
    "output_list = []\n",
    "def pipeline(image):\n",
    "    \n",
    "    image = image\n",
    "    \n",
    "    #get the sliding windows\n",
    "    currentWindows = window_dim(image, frameno)\n",
    "    \n",
    "    #Indices we think are cars:\n",
    "    box_list = search_windows(image, currentWindows, svc, X_scaler,**search_win_params)\n",
    "    \n",
    "    output_image = det.detect_vehicles(image, box_list)\n",
    "    return output_image\n",
    "\n",
    "count = 0\n",
    "test_images = ['./test_images/test1.jpg','./test_images/test2.jpg','./test_images/test3.jpg','./test_images/test4.jpg','./test_images/test5.jpg','./test_images/test6.jpg']\n",
    "draw_images = []\n",
    "\n",
    "test_image = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "for test_image in test_images:\n",
    "    test_img = mpimg.imread(test_image)\n",
    "    currentWindows = window_dim(test_img, frameno)\n",
    "    \n",
    "    #Indices we think are cars:\n",
    "    box_list = search_windows(test_img, currentWindows, svc, X_scaler,**search_win_params_classify23)\n",
    "    \n",
    "    image_with_boxes = draw_boxes(test_img, box_list)\n",
    "    \n",
    "    draw_images.append(image_with_boxes)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c4d3381b707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plt.imshow(output_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
