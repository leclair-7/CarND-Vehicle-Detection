{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from vehicle_detection_utilities import *\n",
    "\n",
    "\n",
    "\n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='YUV', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    on_windows = []    \n",
    "    for window in windows:\n",
    "        \n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))    \n",
    "        features = get_img_features(test_img, **search_win_params_classify)        \n",
    "        test_features = scaler.transform(features.reshape(1, -1))\n",
    "        \n",
    "        prediction = clf.predict(test_features)\n",
    "        \n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "            \n",
    "    return on_windows\n",
    "\n",
    "#GENERATES WINDOWS\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    \n",
    "    imcopy = np.copy(img)\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        \n",
    "        r=random.randint(0,255)\n",
    "        g=random.randint(0,255)\n",
    "        b=random.randint(0,255)        \n",
    "        color=(r, g, b) \n",
    "        \n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classifier Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ron/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.96 Seconds to extract HOG features...\n",
      "4.14 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9804\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import importlib\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "########## GET THE DATA!! ################\n",
    "non_car_data_folder = \"./data/non-vehicles/Extras/*.png\"\n",
    "car_data_folder     = \"./data/vehicles/vehicles/*.png\"\n",
    "car_names     = glob.glob(car_data_folder)\n",
    "non_car_names = glob.glob(non_car_data_folder)\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in car_names:\n",
    "    cars.append(image)\n",
    "for image in non_car_names:\n",
    "    notcars.append(image)\n",
    "\n",
    "cars = shuffle(cars)\n",
    "notcars = shuffle(notcars)\n",
    "\n",
    "# Equal number of train and test images\n",
    "minlen = min(len(cars),len(notcars))\n",
    "cars    = cars[:minlen]\n",
    "notcars = notcars[:minlen]\n",
    "carts   = shuffle(cars)\n",
    "notcars = shuffle(notcars)\n",
    "##########################################\n",
    "    \n",
    "search_win_params_classify = {\n",
    "'color_space' : 'YUV',\n",
    "'spatial_size' : (16,16),\n",
    "'orient' : 9,\n",
    "'pix_per_cell' : 16,\n",
    "'cell_per_block' : 2,\n",
    "'hog_channel' : \"ALL\",\n",
    "'spatial_feat':True, \n",
    "'hist_feat':True, \n",
    "'hog_feat':True\n",
    "}\n",
    "\n",
    "t=time.time()\n",
    "\n",
    "path = \"./carFeatures.p\"\n",
    "if os.path.isfile(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        try:\n",
    "            processed_training_data = pickle.load(f)\n",
    "        except StandardError: # so many things could go wrong, can't be more specific.\n",
    "            pass \n",
    "with open(path, \"wb\") as f:\n",
    "    car_features    = [cv2.cvtColor(cv2.imread(i), cv2.COLOR_BGR2RGB) for i in cars]\n",
    "    notcar_features = [cv2.cvtColor(cv2.imread(i), cv2.COLOR_BGR2RGB) for i in notcars]\n",
    "    car_features    = [get_img_features(i, **search_win_params_classify) for i in car_features]\n",
    "    notcar_features = [get_img_features(i, **search_win_params_classify) for i in notcar_features]\n",
    "\n",
    "    processed_training_data = [car_features,notcar_features]\n",
    "    pickle.dump(processed_training_data, f)\n",
    "\n",
    "t2 = time.time()\n",
    "hogtime = round(t2-t, 2)\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "svc = LinearSVC()\n",
    "\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "accuracy = round(svc.score(X_test, y_test), 4)\n",
    "accuracystr = \"%.4f\" % accuracy\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "class DetectorMediator:\n",
    "    def __init__(self):        \n",
    "        \n",
    "        \n",
    "        self.heatmap = None\n",
    "        self.image = None\n",
    "        self.count = 0\n",
    "        self.deque_len = 15\n",
    "        self.boxes_que = deque(maxlen=self.deque_len)\n",
    "    def add_heat(self, heatmap, bbox_list):\n",
    "        \n",
    "        for box in bbox_list:\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1            \n",
    "        return heatmap\n",
    "    \n",
    "    def apply_threshold(self, threshold):\n",
    "        \n",
    "        checkmap = np.copy(self.heatmap)\n",
    "        checkmap[checkmap <= threshold] = 0        \n",
    "        return checkmap\n",
    "    \n",
    "    def generate_heatmap(self):\n",
    "        '''\n",
    "        Generates the heatmap\n",
    "        \n",
    "        Doesn't return anything because it updates an instance var.\n",
    "        \n",
    "        This may affect runtime\n",
    "        '''\n",
    "        self.heatmap = np.zeros_like(self.image[:,:,0]).astype(np.float64)\n",
    "        for boxCoordList in self.boxes_que:\n",
    "            self.heatmap = self.add_heat(self.heatmap, boxCoordList)\n",
    "    \n",
    "    def draw_labeled_bboxes(self, img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    def detect_vehicles(self, input_image, box_list):\n",
    "        \n",
    "        self.count +=1\n",
    "        \n",
    "        self.image = input_image\n",
    "        \n",
    "        self.boxes_que.append(box_list)\n",
    "        \n",
    "        self.generate_heatmap()\n",
    "        \n",
    "        thresholded_img = self.apply_threshold( 7 )\n",
    "        \n",
    "        labels = label(thresholded_img)\n",
    "        \n",
    "        output_image = self.draw_labeled_bboxes(self.image, labels)\n",
    "        \n",
    "        return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frameno = 0\n",
    "frameno = (frameno + 1) % 5\n",
    "\n",
    "def window_dim(output_img, frameno):\n",
    "    \n",
    "    w_dim = 64\n",
    "    \n",
    "    return slide_window(output_img, x_start_stop=[None, None], y_start_stop=[475, 700], \n",
    "                    xy_window=(w_dim, w_dim), xy_overlap=(0.65, .65)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    #img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    \n",
    "    ###### Convert Image to the space then break it up into channels\n",
    "    ctrans_tosearch = convert_color(img_tosearch, color_space='YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "    ################################################################\n",
    "    \n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    output_windows = []\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                output_windows.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)) )\n",
    "    return output_windows\n",
    "    \n",
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 1\n",
    "\n",
    "#out_img = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient=11, pix_per_cell=16, cell_per_block=2, spatial_size=(16,16), hist_bins=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "draw_images = []\n",
    "\n",
    "test_images = glob.glob('./test_pipeline/*.jpg')\n",
    "\n",
    "detector = DetectorMediator()\n",
    "\n",
    "t = search_win_params_classify\n",
    "\n",
    "windows1 = slide_window(image, x_start_stop=[0, 1280], y_start_stop=[400,464], \n",
    "                    xy_window=(64,64), xy_overlap=(0.15, 0.15))\n",
    "windows4 = slide_window(image, x_start_stop=[0, 1280], y_start_stop=[420,501], \n",
    "                    xy_window=(80,80), xy_overlap=(0.2, 0.2))\n",
    "windows2 = slide_window(image, x_start_stop=[0, 1280], y_start_stop=[450,650], \n",
    "                    xy_window=(96,96), xy_overlap=(0.3, 0.3))\n",
    "windows3 = slide_window(image, x_start_stop=[0, 1280], y_start_stop=[550,700], \n",
    "                    xy_window=(128,128), xy_overlap=(0.5, 0.5))\n",
    "theWindows = windows1 + windows2 + windows3 + windows4\n",
    "\n",
    "\n",
    "def pipeline(input_img):\n",
    "    #test_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)     \n",
    "    \n",
    "    #currentWindows = window_dim(input_img, frameno)    \n",
    "    box_list = search_windows(input_img, theWindows, svc, X_scaler,**search_win_params_classify)     \n",
    "    \n",
    "    #box_list = find_cars(input_img, ystart, ystop, scale, svc, X_scaler, t['orient'], t['pix_per_cell'], t['cell_per_block'], t['spatial_size'], hist_bins=32)\n",
    "    \n",
    "    out_img = detector.detect_vehicles(input_img, box_list)\n",
    "    \n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remember video reads in as RGB\n",
    "cv2 reads in on RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video results.mp4\n",
      "[MoviePy] Writing video results.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 203/251 [01:33<00:22,  2.18it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'results.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "clip2 = clip1.subclip(35,45)\n",
    "white_clip = clip2.fl_image(pipeline)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
